"""
ê°œì„ ëœ AI ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
4ë‹¨ê³„ AI ë¶„ì„ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ ì„œë¹„ìŠ¤
"""
import streamlit as st
import time
from typing import Dict, List, Any, Optional, Tuple
import hashlib

from core.constants import UIConstants, MessageConstants
from core.utils import show_message, create_progress_tracker, update_progress
from core.exceptions import AIAnalysisException
from utils.ai_service import AIService
from services.document_management_service import DocumentManagementService

class AIAnalysisOrchestrator:
    """AI ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - 4ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬"""
    
    def __init__(self, mode: str = "full"):
        """
        ì´ˆê¸°í™”
        Args:
            mode: ë¶„ì„ ëª¨ë“œ ("full", "selection", "quick")
        """
        self.mode = mode
        self.ai_service = AIService()
        self.doc_manager = DocumentManagementService()
    
    def run_complete_analysis(self, user_input: str, selection: str = None) -> Dict[str, Any]:
        """
        ì™„ì „í•œ 4ë‹¨ê³„ AI ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥
            selection: ì„ íƒëœ í…ìŠ¤íŠ¸ (ì˜µì…˜)
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        input_hash = self._generate_input_hash(user_input, selection)
        if self._is_duplicate_analysis(input_hash):
            st.info("ì´ë¯¸ ë¶„ì„ëœ ë‚´ìš©ì…ë‹ˆë‹¤. ê¸°ì¡´ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
            return self._get_cached_result(input_hash)
        
        try:
            # ì§„í–‰ ìƒí™© ì¶”ì ê¸° ì´ˆê¸°í™”
            tracker = create_progress_tracker(4)
            
            st.markdown("### ğŸ”„ AI ë¶„ì„ 4ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤")
            
            # 1ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ê³ ë„í™”
            enhanced_prompt = self._execute_step_1(tracker, user_input, selection)
            
            # 2ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            internal_query, external_query = self._execute_step_2(tracker, enhanced_prompt)
            
            # 3ë‹¨ê³„: ë³‘ë ¬ ê²€ìƒ‰
            internal_refs, external_refs = self._execute_step_3(tracker, internal_query, external_query)
            
            # 4ë‹¨ê³„: ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±
            final_result = self._execute_step_4(tracker, enhanced_prompt, internal_refs, external_refs)
            
            # ê²°ê³¼ ìºì‹± ë° ë°˜í™˜
            analysis_result = {
                'result': final_result,
                'internal_refs': internal_refs,
                'external_refs': external_refs,
                'enhanced_prompt': enhanced_prompt,
                'queries': {'internal': internal_query, 'external': external_query}
            }
            
            self._cache_result(input_hash, analysis_result)
            return analysis_result
            
        except Exception as e:
            st.error(f"âŒ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {str(e)}")
            raise AIAnalysisException("complete_analysis", str(e))
    
    def _execute_step_1(self, tracker: Dict, user_input: str, selection: str = None) -> str:
        """1ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ê³ ë„í™” ì‹¤í–‰"""
        st.markdown("#### ğŸ”„ 1ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ê³ ë„í™”")
        update_progress(tracker, 0, "ğŸ§  ì‚¬ìš©ì ì…ë ¥ì„ AIê°€ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°œì„  ì¤‘...")
        
        try:
            enhanced_prompt = self._refine_prompt(user_input, selection)
            update_progress(tracker, 1, "âœ… 1ë‹¨ê³„ ì™„ë£Œ: í”„ë¡¬í”„íŠ¸ ê³ ë„í™”")
            st.success("âœ… 1ë‹¨ê³„ ì™„ë£Œ: í”„ë¡¬í”„íŠ¸ ê³ ë„í™”")
            
            with st.expander("ğŸ” ê³ ë„í™”ëœ í”„ë¡¬í”„íŠ¸ í™•ì¸"):
                st.markdown(f"**ì›ë³¸ ì…ë ¥:**\n{user_input}")
                if selection:
                    st.markdown(f"**ì„ íƒëœ í…ìŠ¤íŠ¸:**\n{selection}")
                st.markdown(f"**AI ê³ ë„í™” í”„ë¡¬í”„íŠ¸:**\n{enhanced_prompt}")
            
            return enhanced_prompt
            
        except Exception as e:
            raise AIAnalysisException("prompt_enhancement", str(e))
    
    def _execute_step_2(self, tracker: Dict, enhanced_prompt: str) -> Tuple[str, str]:
        """2ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹¤í–‰"""
        st.markdown("#### ğŸ” 2ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±")
        update_progress(tracker, 1, "ğŸ” ì‚¬ë‚´/ì™¸ë¶€ ê²€ìƒ‰ì— ìµœì í™”ëœ ì¿¼ë¦¬ ìƒì„± ì¤‘...")
        
        try:
            internal_query, external_query = self._generate_queries(enhanced_prompt)
            update_progress(tracker, 2, "âœ… 2ë‹¨ê³„ ì™„ë£Œ: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±")
            st.success("âœ… 2ë‹¨ê³„ ì™„ë£Œ: ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±")
            
            with st.expander("ğŸ” ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¸"):
                st.markdown(f"**ì‚¬ë‚´ ë¬¸ì„œ ê²€ìƒ‰ ì¿¼ë¦¬:**\n{internal_query}")
                st.markdown(f"**ì™¸ë¶€ ìë£Œ ê²€ìƒ‰ ì¿¼ë¦¬:**\n{external_query}")
            
            return internal_query, external_query
            
        except Exception as e:
            raise AIAnalysisException("query_generation", str(e))
    
    def _execute_step_3(self, tracker: Dict, internal_query: str, external_query: str) -> Tuple[List[Dict], List[Dict]]:
        """3ë‹¨ê³„: ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ - 150ì ë¯¸ë¦¬ë³´ê¸°ì™€ í•¨ê»˜"""
        st.markdown("#### ï¿½ 3ë‹¨ê³„: ì‚¬ë‚´/ì™¸ë¶€ ë ˆí¼ëŸ°ìŠ¤ ë³‘ë ¬ ê²€ìƒ‰")
        update_progress(tracker, 2, "ğŸ“š ì‚¬ë‚´ ë¬¸ì„œ ë° ì™¸ë¶€ ìë£Œë¥¼ ë™ì‹œ ê²€ìƒ‰ ì¤‘...")
        
        try:
            internal_refs, external_refs = self._parallel_reference_search(internal_query, external_query)
            update_progress(tracker, 3, f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: ì‚¬ë‚´ ë¬¸ì„œ {len(internal_refs)}ê°œ, ì™¸ë¶€ ìë£Œ {len(external_refs)}ê°œ ë°œê²¬")
            st.success(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: ì‚¬ë‚´ ë¬¸ì„œ {len(internal_refs)}ê°œ, ì™¸ë¶€ ìë£Œ {len(external_refs)}ê°œ ë°œê²¬")
            
            # ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ë¯¸ë¦¬ë³´ê¸° (150ìì”©)
            self._display_enhanced_search_preview(internal_refs, external_refs)
            
            return internal_refs, external_refs
            
        except Exception as e:
            raise AIAnalysisException("parallel_search", str(e))
    
    def _execute_step_4(self, tracker: Dict, enhanced_prompt: str, internal_refs: List[Dict], external_refs: List[Dict]) -> str:
        """4ë‹¨ê³„: ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        st.markdown("#### ğŸ”„ 4ë‹¨ê³„: ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±")
        update_progress(tracker, 3, "ğŸ¤– ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… AI ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
        
        try:
            # ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            document_content = self._get_analysis_target_content()
            final_result = self._generate_final_result(enhanced_prompt, internal_refs, external_refs, document_content)
            update_progress(tracker, 4, "âœ… ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
            st.success("âœ… 4ë‹¨ê³„ ì™„ë£Œ: ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±")
            
            return final_result
            
        except Exception as e:
            raise AIAnalysisException("result_generation", str(e))
    
    def _refine_prompt(self, user_input: str, selection: str = None) -> str:
        """í”„ë¡¬í”„íŠ¸ ê³ ë„í™”"""
        # ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš© í™•ì¸
        if selection and selection.strip():
            # ë¶„ì„í•  ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°
            context = f"ì‚¬ìš©ì ìš”ì²­: {user_input}\n\në¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš©:\n{selection[:2000]}..."
            if len(selection) > 2000:
                context += f"\n(ë¬¸ì„œ ì´ ê¸¸ì´: {len(selection):,}ì)"
        else:
            # ë¬¸ì„œ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš° í˜„ì¬ ì„¸ì…˜ì˜ ë¬¸ì„œ ë‚´ìš© ì‹œë„
            document_content = st.session_state.get('document_content', '')
            if document_content and document_content.strip():
                context = f"ì‚¬ìš©ì ìš”ì²­: {user_input}\n\në¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš©:\n{document_content[:2000]}..."
                if len(document_content) > 2000:
                    context += f"\n(ë¬¸ì„œ ì´ ê¸¸ì´: {len(document_content):,}ì)"
            else:
                context = f"ì‚¬ìš©ì ìš”ì²­: {user_input}\n\nì£¼ì˜: ë¶„ì„í•  ë¬¸ì„œ ë‚´ìš©ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        try:
            return self.ai_service.refine_user_prompt(context)
        except Exception as e:
            st.warning(f"í”„ë¡¬í”„íŠ¸ ê³ ë„í™” ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {str(e)}")
            return user_input
    
    def _generate_queries(self, enhanced_prompt: str) -> Tuple[str, str]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        try:
            queries = self.ai_service.generate_search_queries(enhanced_prompt)
            internal_query = queries.get('internal', enhanced_prompt)
            external_query = queries.get('external', enhanced_prompt)
            return internal_query, external_query
        except Exception as e:
            st.warning(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {str(e)}")
            return enhanced_prompt, enhanced_prompt
    
    def _parallel_reference_search(self, internal_query: str, external_query: str) -> Tuple[List[Dict], List[Dict]]:
        """ë³‘ë ¬ ë ˆí¼ëŸ°ìŠ¤ ê²€ìƒ‰"""
        internal_refs = []
        external_refs = []
        
        # ì‚¬ë‚´ ë¬¸ì„œ ê²€ìƒ‰
        try:
            docs = self.doc_manager.search_training_documents(internal_query, top=10)
            internal_refs = self._convert_docs_for_ai(docs)
        except Exception as e:
            st.warning(f"ì‚¬ë‚´ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        # ì™¸ë¶€ ìë£Œ ê²€ìƒ‰
        try:
            external_results = self.ai_service.search_external_references(external_query)
            external_refs = external_results if external_results else []
        except Exception as e:
            st.warning(f"ì™¸ë¶€ ìë£Œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        return internal_refs, external_refs
    
    def _get_analysis_target_content(self) -> str:
        """ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        # í˜„ì¬ ì„¸ì…˜ì— ì €ì¥ëœ ë¶„ì„ í…ìŠ¤íŠ¸ í™•ì¸
        analysis_text = st.session_state.get('analysis_text', '')
        
        if analysis_text and analysis_text.strip():
            return analysis_text
        
        # í˜„ì¬ ë¬¸ì„œ ë‚´ìš© í™•ì¸
        document_content = st.session_state.get('document_content', '')
        if document_content and document_content.strip():
            return document_content
        
        # ì„ íƒëœ í…ìŠ¤íŠ¸ í™•ì¸
        selected_text = st.session_state.get('selected_text', '')
        if selected_text and selected_text.strip():
            return selected_text
        
        return ""

    def _generate_final_result(self, enhanced_prompt: str, internal_refs: List[Dict], external_refs: List[Dict], document_content: str = "") -> str:
        """ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„± - ë¬¸ì„œ ë‚´ìš© í¬í•¨"""
        try:
            return self.ai_service.generate_comprehensive_analysis(
                query=enhanced_prompt,
                internal_docs=internal_refs,
                external_docs=external_refs,
                document_content=document_content  # ì‹¤ì œ ë¶„ì„í•  ë¬¸ì„œ ë‚´ìš© ì¶”ê°€
            )
        except Exception as e:
            raise AIAnalysisException("final_result", f"ìµœì¢… ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def _convert_docs_for_ai(self, docs: List[Dict]) -> List[Dict]:
        """ë¬¸ì„œ ê´€ë¦¬ ì„œë¹„ìŠ¤ì˜ ë¬¸ì„œ í˜•ì‹ì„ AI ì„œë¹„ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        converted_docs = []
        for doc in docs:
            converted_doc = {
                "id": doc.get("file_id", "unknown"),
                "title": doc.get("title", "ì œëª© ì—†ìŒ"),
                "content": doc.get("content", ""),
                "summary": doc.get("summary", ""),
                "source_detail": f"ì‚¬ë‚´ ë¬¸ì„œ - {doc.get('filename', 'Unknown')}",
                "relevance_score": doc.get("search_score", 0.5) / 10 if doc.get("search_score") else 0.5,
                "search_type": "company_docs"
            }
            converted_docs.append(converted_doc)
        return converted_docs
    
    def _display_enhanced_search_preview(self, internal_refs: List[Dict], external_refs: List[Dict]):
        """ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ (150ìì”©)"""
        with st.expander("ğŸ” ê²€ìƒ‰ëœ ë ˆí¼ëŸ°ìŠ¤ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ğŸ“ ì‚¬ë‚´ ë¬¸ì„œ ê²°ê³¼**")
                if internal_refs:
                    for i, doc in enumerate(internal_refs[:3], 1):
                        title = doc.get('title', 'N/A')
                        content = doc.get('content', '')
                        
                        st.markdown(f"**{i}. {title}**")
                        if content:
                            preview = content[:150]
                            if len(content) > 150:
                                preview += "..."
                            st.markdown(f"*{preview}*")
                        st.markdown("---")
                else:
                    st.markdown("*ê²€ìƒ‰ëœ ì‚¬ë‚´ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.*")
                    
            with col2:
                st.markdown("**ğŸŒ ì™¸ë¶€ ìë£Œ ê²°ê³¼**")
                if external_refs:
                    for i, doc in enumerate(external_refs[:3], 1):
                        title = doc.get('title', 'N/A')
                        content = doc.get('content', '')
                        
                        st.markdown(f"**{i}. {title}**")
                        if content:
                            preview = content[:150]
                            if len(content) > 150:
                                preview += "..."
                            st.markdown(f"*{preview}*")
                        st.markdown("---")
                else:
                    st.markdown("*ê²€ìƒ‰ëœ ì™¸ë¶€ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.*")
    
    def _generate_input_hash(self, user_input: str, selection: str = None) -> str:
        """ì…ë ¥ í•´ì‹œ ìƒì„±"""
        combined_input = user_input + (selection or "")
        return hashlib.md5(combined_input.encode()).hexdigest()
    
    def _is_duplicate_analysis(self, input_hash: str) -> bool:
        """ì¤‘ë³µ ë¶„ì„ í™•ì¸"""
        return st.session_state.get('last_analysis_hash') == input_hash
    
    def _cache_result(self, input_hash: str, result: Dict[str, Any]):
        """ê²°ê³¼ ìºì‹±"""
        st.session_state.last_analysis_hash = input_hash
        st.session_state.ai_analysis_references = {
            "internal": result['internal_refs'], 
            "external": result['external_refs']
        }
        st.session_state.ai_analysis_result = result['result']
    
    def _get_cached_result(self, input_hash: str) -> Dict[str, Any]:
        """ìºì‹œëœ ê²°ê³¼ ë°˜í™˜"""
        return {
            'result': st.session_state.get('ai_analysis_result', ''),
            'internal_refs': st.session_state.get('ai_analysis_references', {}).get('internal', []),
            'external_refs': st.session_state.get('ai_analysis_references', {}).get('external', [])
        }