"""
AI ì„œë¹„ìŠ¤ ëª¨ë“ˆ - ê°„ì†Œí™”ëœ ë²„ì „ (ë¦¬íŒ©í† ë§ìš©)
"""
import openai
import streamlit as st
import json
from typing import List, Dict, Any, Optional
from config import AI_CONFIG, TAVILY_CONFIG

class AIService:
    """AI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.client = None
        self._initialize_openai_client()
    
    def _initialize_openai_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            if AI_CONFIG.get("openai_api_key") and AI_CONFIG.get("openai_endpoint"):
                self.client = openai.AzureOpenAI(
                    api_key=AI_CONFIG["openai_api_key"],
                    azure_endpoint=AI_CONFIG["openai_endpoint"],
                    api_version=AI_CONFIG["api_version"]
                )
        except Exception as e:
            st.warning(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def refine_user_prompt(self, context: str) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ê³ ë„í™”"""
        if not self.client:
            return context
            
        try:
            response = self.client.chat.completions.create(
                model=AI_CONFIG["deployment_name"],
                messages=[
                    {"role": "system", "content": "ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë” êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ ê°œì„ í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": f"ë‹¤ìŒ ìš”ì²­ì„ ê°œì„ í•´ì£¼ì„¸ìš”: {context}"}
                ],
                max_tokens=500,
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            st.warning(f"í”„ë¡¬í”„íŠ¸ ê³ ë„í™” ì‹¤íŒ¨: {str(e)}")
            return context
    
    def generate_search_queries(self, enhanced_prompt: str) -> Dict[str, str]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        if not self.client:
            return {"internal": enhanced_prompt, "external": enhanced_prompt}
            
        try:
            response = self.client.chat.completions.create(
                model=AI_CONFIG["deployment_name"],
                messages=[
                    {"role": "system", "content": "ì‚¬ë‚´ ë¬¸ì„œ ê²€ìƒ‰ìš©ê³¼ ì™¸ë¶€ ê²€ìƒ‰ìš© ì¿¼ë¦¬ë¥¼ ê°ê° ìƒì„±í•´ì£¼ì„¸ìš”. JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”."},
                    {"role": "user", "content": f"ìš”ì²­: {enhanced_prompt}"}
                ],
                max_tokens=300,
                temperature=0.3
            )
            
            result = response.choices[0].message.content
            try:
                queries = json.loads(result)
                return {
                    "internal": queries.get("internal", enhanced_prompt),
                    "external": queries.get("external", enhanced_prompt)
                }
            except:
                return {"internal": enhanced_prompt, "external": enhanced_prompt}
                
        except Exception as e:
            st.warning(f"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {"internal": enhanced_prompt, "external": enhanced_prompt}
    
    def search_external_references(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """ì™¸ë¶€ ë ˆí¼ëŸ°ìŠ¤ ê²€ìƒ‰ (Tavily ë˜ëŠ” ë”ë¯¸ ë°ì´í„°)"""
        try:
            if TAVILY_CONFIG.get("api_key"):
                # Tavily API ì‚¬ìš© (ì‹¤ì œ êµ¬í˜„ ì‹œ)
                return self._search_with_tavily(query, max_results)
            else:
                # ë”ë¯¸ ë°ì´í„° ë°˜í™˜
                return self._get_dummy_external_results(query, max_results)
        except Exception as e:
            st.warning(f"ì™¸ë¶€ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _search_with_tavily(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """Tavilyë¥¼ ì‚¬ìš©í•œ ì™¸ë¶€ ê²€ìƒ‰"""
        try:
            # Tavily API ì‚¬ìš© (requests ì‚¬ìš©)
            import requests
            
            api_key = TAVILY_CONFIG.get("api_key")
            if not api_key:
                st.warning("Tavily API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return self._get_dummy_external_results(query, max_results)
            
            # Tavily API ìš”ì²­
            url = "https://api.tavily.com/search"
            headers = {
                "Content-Type": "application/json"
            }
            
            data = {
                "api_key": api_key,
                "query": query,
                "search_depth": TAVILY_CONFIG.get("search_depth", "basic"),
                "max_results": max_results,
                "include_answer": True,
                "include_raw_content": False
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                
                # Tavily ê²°ê³¼ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                external_results = []
                if "results" in result:
                    for i, item in enumerate(result["results"][:max_results]):
                        external_results.append({
                            "id": f"tavily_{i}",
                            "title": item.get("title", "ì œëª© ì—†ìŒ"),
                            "content": item.get("content", "")[:500],  # 500ì ì œí•œ
                            "url": item.get("url", ""),
                            "score": item.get("score", 0.5),
                            "source": "Tavily Search",
                            "source_detail": f"Tavily - {item.get('url', '')}",
                            "search_type": "external_web"
                        })
                
                st.info(f"âœ… Tavilyë¡œ {len(external_results)}ê°œì˜ ì™¸ë¶€ ìë£Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                return external_results
            else:
                st.warning(f"Tavily API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return self._get_dummy_external_results(query, max_results)
                
        except Exception as e:
            st.warning(f"Tavily ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._get_dummy_external_results(query, max_results)
    
    def _get_dummy_external_results(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """ë”ë¯¸ ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ (Tavily API ì—†ì„ ë•Œ)"""
        import random
        
        # ë” ë‹¤ì–‘í•˜ê³  í˜„ì‹¤ì ì¸ ë”ë¯¸ ë°ì´í„°
        dummy_templates = [
            {
                "source": "Wikipedia",
                "title_format": "{query} - ìœ„í‚¤ë°±ê³¼",
                "content_format": "{query}ì— ëŒ€í•œ ë°±ê³¼ì‚¬ì „ì  ì •ë³´ì…ë‹ˆë‹¤. ì—­ì‚¬ì  ë°°ê²½, ì •ì˜, íŠ¹ì§• ë“±ì„ í¬í•¨í•œ ì¢…í•©ì ì¸ ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” ê²€ì¦ëœ ì •ë³´ì›ì—ì„œ ìˆ˜ì§‘ëœ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.",
                "url_format": "https://ko.wikipedia.org/wiki/{query}"
            },
            {
                "source": "Stack Overflow",
                "title_format": "{query} êµ¬í˜„ ë°©ë²• - ê°œë°œì ì»¤ë®¤ë‹ˆí‹°",
                "content_format": "{query}ì™€ ê´€ë ¨ëœ ì‹¤ì œ ê°œë°œ ê²½í—˜ê³¼ í•´ê²°ì±…ì„ ê³µìœ í•˜ëŠ” ê°œë°œìë“¤ì˜ í† ë¡ ì…ë‹ˆë‹¤. ì½”ë“œ ì˜ˆì œ, ëª¨ë²” ì‚¬ë¡€, ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ë°©ë²•ì„ í¬í•¨í•©ë‹ˆë‹¤.",
                "url_format": "https://stackoverflow.com/questions/tagged/{query}"
            },
            {
                "source": "Medium",
                "title_format": "{query} íŠ¸ë Œë“œ ë¶„ì„ - ì „ë¬¸ê°€ ë¸”ë¡œê·¸",
                "content_format": "{query}ì— ëŒ€í•œ ìµœì‹  íŠ¸ë Œë“œì™€ ì „ë¬¸ê°€ ì˜ê²¬ì„ ì œê³µí•˜ëŠ” ê¸°ìˆ  ë¸”ë¡œê·¸ì…ë‹ˆë‹¤. ì‹¤ë¬´ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì¸ì‚¬ì´íŠ¸ì™€ í–¥í›„ ì „ë§ì„ ë‹¤ë£¹ë‹ˆë‹¤.",
                "url_format": "https://medium.com/topic/{query}"
            },
            {
                "source": "GitHub",
                "title_format": "{query} ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸",
                "content_format": "{query}ì™€ ê´€ë ¨ëœ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ë° ì½”ë“œ ì €ì¥ì†Œì…ë‹ˆë‹¤. ì‹¤ì œ êµ¬í˜„ ì˜ˆì œ, ë¼ì´ë¸ŒëŸ¬ë¦¬, ë„êµ¬ ë“±ì„ í¬í•¨í•˜ì—¬ ê°œë°œì— ì§ì ‘ í™œìš©í•  ìˆ˜ ìˆëŠ” ìë£Œì…ë‹ˆë‹¤.",
                "url_format": "https://github.com/topics/{query}"
            },
            {
                "source": "Academic Paper",
                "title_format": "{query} ì—°êµ¬ ë…¼ë¬¸ - í•™ìˆ  ìë£Œ",
                "content_format": "{query}ì— ëŒ€í•œ í•™ìˆ ì  ì—°êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤. ì²´ê³„ì ì¸ ì—°êµ¬ ë°©ë²•ë¡ ê³¼ ì‹¤ì¦ì  ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì „ë¬¸ì ì¸ ë¶„ì„ê³¼ ê²°ë¡ ì„ ì œê³µí•©ë‹ˆë‹¤.",
                "url_format": "https://scholar.google.com/scholar?q={query}"
            }
        ]
        
        results = []
        for i in range(min(max_results, len(dummy_templates))):
            template = dummy_templates[i]
            results.append({
                "id": f"dummy_ext_{i+1}",
                "title": template["title_format"].format(query=query),
                "content": template["content_format"].format(query=query),
                "url": template["url_format"].format(query=query.replace(" ", "-")),
                "score": 0.9 - (i * 0.15),
                "source": template["source"],
                "source_detail": f"{template['source']} (ë°ëª¨ ë°ì´í„°)",
                "search_type": "external_demo"
            })
        
        st.info(f"ğŸ”„ ë°ëª¨ ëª¨ë“œ: {len(results)}ê°œì˜ ë”ë¯¸ ì™¸ë¶€ ìë£Œ ìƒì„± (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Tavily API ì‚¬ìš©)")
        return results
    
    def generate_comprehensive_analysis(self, query: str, internal_docs: List[Dict], external_docs: List[Dict], document_content: str = "") -> str:
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± - ë¬¸ì„œ ë‚´ìš© í¬í•¨"""
        if not self.client:
            return self._get_dummy_analysis(query, internal_docs, external_docs, document_content)
            
        try:
            # ë¶„ì„í•  ë¬¸ì„œ ë‚´ìš©ê³¼ ì°¸ê³  ìë£Œë¥¼ í¬í•¨í•œ ì™„ì „í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self._build_comprehensive_context(query, document_content, internal_docs, external_docs)
            
            response = self.client.chat.completions.create(
                model=AI_CONFIG["deployment_name"],
                messages=[
                    {"role": "system", "content": "ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ê³ , ì‚¬ë‚´ ë¬¸ì„œì™€ ì™¸ë¶€ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ í¬ê´„ì ì´ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": context}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            return response.choices[0].message.content
            
        except Exception as e:
            st.warning(f"ì¢…í•© ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return self._get_dummy_analysis(query, internal_docs, external_docs, document_content)
    
    def _build_comprehensive_context(self, query: str, document_content: str, internal_docs: List[Dict], external_docs: List[Dict]) -> str:
        """í¬ê´„ì ì¸ ë¶„ì„ìš© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context = f"ì‚¬ìš©ì ìš”ì²­: {query}\n\n"
        
        # ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš© (ê°€ì¥ ì¤‘ìš”!)
        if document_content and document_content.strip():
            context += f"===== ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš© =====\n{document_content}\n\n"
        else:
            context += "===== ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ ë‚´ìš© =====\n(ë¬¸ì„œ ë‚´ìš©ì´ ì œê³µë˜ì§€ ì•ŠìŒ)\n\n"
        
        # ì‚¬ë‚´ ì°¸ê³  ë¬¸ì„œ
        if internal_docs:
            context += "===== ì‚¬ë‚´ ì°¸ê³  ë¬¸ì„œ =====\n"
            for i, doc in enumerate(internal_docs[:3], 1):
                title = doc.get('title', 'N/A')
                content = doc.get('content', '')[:300]  # 300ìê¹Œì§€
                context += f"{i}. {title}\n{content}...\n\n"
        
        # ì™¸ë¶€ ì°¸ê³  ìë£Œ
        if external_docs:
            context += "===== ì™¸ë¶€ ì°¸ê³  ìë£Œ =====\n"
            for i, doc in enumerate(external_docs[:3], 1):
                title = doc.get('title', 'N/A')
                content = doc.get('content', '')[:300]  # 300ìê¹Œì§€
                context += f"{i}. {title}\n{content}...\n\n"
        
        context += "ìœ„ì˜ ë¬¸ì„œ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•˜ë˜, ì°¸ê³  ìë£Œë“¤ì„ í™œìš©í•˜ì—¬ í¬ê´„ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."
        return context

    def _build_analysis_context(self, internal_docs: List[Dict], external_docs: List[Dict]) -> str:
        """ê¸°ì¡´ ë¶„ì„ìš© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í•˜ìœ„ í˜¸í™˜ì„±)"""
        context = ""
        
        if internal_docs:
            context += "**ì‚¬ë‚´ ë¬¸ì„œ:**\n"
            for doc in internal_docs[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                context += f"- {doc.get('title', 'N/A')}: {doc.get('content', '')[:200]}...\n"
        
        if external_docs:
            context += "\n**ì™¸ë¶€ ìë£Œ:**\n"
            for doc in external_docs[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                context += f"- {doc.get('title', 'N/A')}: {doc.get('content', '')[:200]}...\n"
        
        return context
    
    def _get_dummy_analysis(self, query: str, internal_docs: List[Dict], external_docs: List[Dict], document_content: str = "") -> str:
        """ë”ë¯¸ ë¶„ì„ ê²°ê³¼ - ë¬¸ì„œ ë‚´ìš© í¬í•¨"""
        doc_info = ""
        if document_content and document_content.strip():
            word_count = len(document_content.split())
            char_count = len(document_content)
            doc_info = f"\n\n**ğŸ“„ ë¶„ì„ëœ ë¬¸ì„œ ì •ë³´:**\n- ê¸€ììˆ˜: {char_count:,}ì\n- ë‹¨ì–´ìˆ˜: {word_count:,}ë‹¨ì–´\n- ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°: {document_content[:200]}..."
        
        return f"""
## ğŸ“‹ AI ë¶„ì„ ê²°ê³¼

**ì‚¬ìš©ì ìš”ì²­:** {query}{doc_info}

### ğŸ” ì¢…í•© ë¶„ì„
ì‚¬ë‚´ ë¬¸ì„œ {len(internal_docs)}ê°œì™€ ì™¸ë¶€ ìë£Œ {len(external_docs)}ê°œë¥¼ ì°¸ê³ í•˜ì—¬ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

### ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸
1. **í•µì‹¬ í¬ì¸íŠ¸**: {query}ì™€ ê´€ë ¨í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì¤‘ìš”í•œ ì ë“¤ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.
2. **ì‚¬ë‚´ ê´€ì **: ìš°ë¦¬ ì¡°ì§ì˜ ë¬¸ì„œë“¤ì—ì„œëŠ” ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì„ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.
3. **ì—…ê³„ ë™í–¥**: ì™¸ë¶€ ìë£Œë“¤ì€ ìµœì‹  íŠ¸ë Œë“œì™€ ëª¨ë²” ì‚¬ë¡€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

### ğŸ¯ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­
ë¶„ì„ëœ ìë£Œë“¤ì„ ì¢…í•©í•˜ë©´, ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤.

*(ì‹¤ì œ AI ë¶„ì„ ê²°ê³¼ëŠ” OpenAI API ì—°ê²° í›„ ì œê³µë©ë‹ˆë‹¤)*
        """.strip()
    
    def test_ai_connection(self) -> Dict[str, Any]:
        """AI ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.client:
            return {"available": False, "error": "OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨"}
        
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
            response = self.client.chat.completions.create(
                model=AI_CONFIG["deployment_name"],
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10
            )
            return {"available": True, "model": AI_CONFIG["deployment_name"]}
        except Exception as e:
            return {"available": False, "error": str(e)}